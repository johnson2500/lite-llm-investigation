# Alternative configuration using NodePort instead of Ingress
# Use this for easier local/development access

replicaCount: 1

image:
  repository: ghcr.io/berriai/litellm
  pullPolicy: IfNotPresent
  tag: "v1.80.5-stable"

service:
  type: NodePort
  port: 4000
  nodePort: 30400  # Access via http://<node-ip>:30400

ingress:
  enabled: false  # Disable ingress when using NodePort

litellm:
  debug: true
  config:
    model_list:
      - model_name: llama3
        litellm_params:
          model: ollama/llama3
          api_base: http://host.containers.internal:11434

